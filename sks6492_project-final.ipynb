{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sks6492_project3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JL7CjUa-P8Mt",
        "outputId": "5327488c-a46b-41a3-9ea8-de1ba962eaef"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQcOEptRQHaq"
      },
      "source": [
        "# Parameters employed:\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from scipy.stats import skew\n",
        "from scipy.special import boxcox1p\n",
        "from scipy.stats import boxcox_normmax\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV, Lasso\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from mlxtend.regressor import StackingCVRegressor\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlKB7C_9QQNw"
      },
      "source": [
        "# Loading training and testing data:\n",
        "all_path = \"/content/gdrive/My Drive/DM_Project_1/train.csv\"\n",
        "X_train_all = pd.read_csv(all_path)\n",
        "test_path = \"/content/gdrive/My Drive/DM_Project_1/test.csv\"\n",
        "test_data = pd.read_csv(test_path)\n",
        "X_test_all = test_data.copy()\n",
        "\n",
        "# Unwanted features:\n",
        "uw_list = [\"Id\", \"val_kf\", \"SalePrice\"]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMGUP_uCQzTa"
      },
      "source": [
        "def feats_trfm(comp_features):\n",
        "  new_feats = comp_features.copy()\n",
        "\n",
        "  # Converting certain features to string type\n",
        "  for cols in ['YrSold', 'MoSold', 'MSSubClass']:\n",
        "    new_feats[cols] = new_feats[cols].astype(str)\n",
        "  \n",
        "  # Finding Numerical Columns and replacing NaN's with median:\n",
        "  num_cols = [col for col in new_feats.columns if new_feats[col].dtype != 'object' and col not in uw_list]\n",
        "  for cols in num_cols:\n",
        "    new_feats[cols] = new_feats.groupby(\"Neighborhood\")[cols].transform(lambda x: x.fillna(x.median()))\n",
        "\n",
        "  # Finding Categorical Columns and replacing NaN's with \"Missing\":\n",
        "  categ_cols = [col for col in new_feats.columns if new_feats[col].dtype == 'object']\n",
        "  for cols in categ_cols:\n",
        "    new_feats[cols] = new_feats[cols].fillna(\"Missing\")\n",
        "  \n",
        "  # Simple feature engineering:\n",
        "  new_feats['HouseSFOverall'] = new_feats['TotalBsmtSF']+new_feats['1stFlrSF']+new_feats['2ndFlrSF']\n",
        "  new_feats['LotCompAr'] = new_feats['LotFrontage']+new_feats['LotArea']\n",
        "  new_feats['BsmtFinComp'] = new_feats['BsmtFinSF1']+new_feats['BsmtFinSF2']\n",
        "  new_feats['BathComp'] = new_feats['FullBath']+new_feats['HalfBath']\n",
        "  new_feats['PorchComp'] = new_feats['OpenPorchSF']+new_feats['EnclosedPorch']+new_feats['ScreenPorch']\n",
        "\n",
        "  # Label encoding required columns:\n",
        "  reqd_cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', 'ExterQual', 'ExterCond','HeatingQC', \\\n",
        "               'PoolQC', 'KitchenQual', 'BsmtFinType1', 'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', \\\n",
        "               'LandSlope', 'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'YrSold', 'MoSold')\n",
        "  for col in reqd_cols:\n",
        "    lbl = LabelEncoder() \n",
        "    lbl.fit(list(new_feats[col].values)) \n",
        "    new_feats[col] = lbl.transform(list(new_feats[col].values))\n",
        "\n",
        "  # Replacing lower count features with string \"Sparse\"\n",
        "  categ_cols = [col for col in new_feats.columns if new_feats[col].dtype == 'object']   \n",
        "  for col in categ_cols:\n",
        "    new_dict = new_feats[col].value_counts().to_dict()\n",
        "    for key, value in new_dict.items():\n",
        "      if value/len(new_feats[col]) < 0.02:\n",
        "        new_feats.loc[:,col][new_feats[col] == key] = \"Sparse\"\n",
        "\n",
        "  # Compute the skew values and based on the threshold apply the transformation:\n",
        "  num_cols = [col for col in new_feats.columns if new_feats[col].dtype != 'object' and col not in uw_list]\n",
        "  skew_thresh = new_feats[num_cols].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
        "  skew_pd = pd.DataFrame({'Skew' :skew_thresh})\n",
        "  skew_ind = skew_pd[abs(skew_pd) > 0.75].index\n",
        "  for feat in skew_ind:\n",
        "    new_feats[feat] = boxcox1p(new_feats[feat], 0.15)\n",
        "\n",
        "  return new_feats"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN6K_tdEjjSy"
      },
      "source": [
        "# Processing & Transformation of Train/Test features:\n",
        "Test_Trfm_Feats = feats_trfm(X_test_all)\n",
        "Test_Trfm_Feats.fillna(0, inplace=True) \n",
        "\n",
        "def train_model(fold, model, model_name, is_stack=False):\n",
        "\n",
        "  # Defining 4 fold:\n",
        "  kfolds = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
        "  X_train_all['val_kf'] = -1\n",
        "  \n",
        "  for idx, (Train_Ind, Val_Ind) in enumerate(kfolds.split(X_train_all, X_train_all['SalePrice'])):\n",
        "    X_train_all.loc[Val_Ind, 'val_kf'] = idx\n",
        "    \n",
        "  Train_Trfm_Feats = feats_trfm(X_train_all)\n",
        "  Train_Trfm_Feats['SalePrice'] = np.log1p(Train_Trfm_Feats['SalePrice'])\n",
        "\n",
        "  # Concatenation of Train & Test Data, and apply Get_Dummies\n",
        "  All_Trfm_Feats = pd.concat([Train_Trfm_Feats, Test_Trfm_Feats])\n",
        "  All_Trfm_Feats = pd.get_dummies(All_Trfm_Feats)  \n",
        "  Test_Data = All_Trfm_Feats.tail(1459)\n",
        "  All_Data = All_Trfm_Feats.head(1460)\n",
        "  reqd_cols = [col for col in All_Data.columns if col not in uw_list]    \n",
        "\n",
        "  # Split Train & Validation Data:\n",
        "  Train_Data = All_Data[All_Data['val_kf'] != fold].reset_index(drop=True)\n",
        "  Train_Data = Train_Data[Train_Data['GrLivArea'] < 4500]\n",
        "  Train_Data = Train_Data.reset_index(drop=True)\n",
        "  Valid_Data = All_Data[All_Data['val_kf'] == fold].reset_index(drop=True)\n",
        "\n",
        "  # Train stack and other models:\n",
        "  if is_stack:\n",
        "    model.fit(Train_Data[reqd_cols].values, Train_Data['SalePrice'])\n",
        "  else:\n",
        "    model.fit(Train_Data[reqd_cols].values, Train_Data['SalePrice'])\n",
        "  \n",
        "  print('{} Validation Root Mean Square Error : {}'.format(model_name, mean_squared_error(Valid_Data['SalePrice'], \\\n",
        "                                                                                          model.predict(Valid_Data[reqd_cols].values), squared=False)))\n",
        "  return model.predict(Test_Data[reqd_cols].values)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_MRO_twqwDJ",
        "outputId": "81023b8c-855d-483c-c618-5a747c20bd9f"
      },
      "source": [
        "print('Training LGBM, XGB, E-NET, SVR, GBR, RIDGE, LASSO & STACK GEN ...')\n",
        "\n",
        "Test_Pred = pd.DataFrame()\n",
        "for fold in range(3):\n",
        "  model_xgb = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bytree=0.7, gamma=0, importance_type='gain', objective='reg:linear', learning_rate=0.02, \\\n",
        "                         max_delta_step=0, max_depth=4, min_child_weight=1, n_estimators=1000, num_parallel_tree=1, random_state=42, reg_alpha=0.00007, \\\n",
        "                         reg_lambda=1, scale_pos_weight=1, subsample=0.8, tree_method='exact', validate_parameters=1)\n",
        "  Test_Pred[\"xgboost\" + str(fold) + \"fld\"] = train_model(fold, model_xgb, 'XGBoost') \n",
        "\n",
        "  model_ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=[14.5, 14.7, 14.9, 15, 15.1, 15.3, 15.5])) \n",
        "  Test_Pred[\"ridge\" + str(fold) + \"fld\"] = train_model(fold, model_ridge, 'Ridge') \n",
        "\n",
        "  model_lasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e+7, alphas=[0.00005, 0.0001, 0.0003, 0.0005, 0.0007, 0.0008], random_state=42))\n",
        "  Test_Pred[\"lasso\" + str(fold) + \"fld\"] = train_model(fold, model_lasso, 'Lasso') \n",
        "\n",
        "  model_enet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e+7, alphas=[0.0001, 0.0002, 0.0004, 0.0005, 0.0007], l1_ratio=[0.8, 0.9, 0.99, 1]))\n",
        "  Test_Pred[\"elasticnet\" + str(fold) + \"fld\"] = train_model(fold, model_enet, 'ElasticNet') \n",
        "\n",
        "  model_gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, \\\n",
        "                                      min_samples_split=10, loss='huber', random_state=42)\n",
        "  Test_Pred[\"gradb\" + str(fold) + \"fld\"] = train_model(fold, model_gbr, 'GradientBoost') \n",
        "\n",
        "  model_svr = make_pipeline(RobustScaler(), SVR(C=20, epsilon=0.008, gamma=0.0003))\n",
        "  Test_Pred[\"svr\" + str(fold) + \"fld\"] = train_model(fold, model_svr, 'SVR') \n",
        "\n",
        "  model_stack_gen = StackingCVRegressor(regressors=(model_ridge, model_lasso, model_enet, model_gbr, model_xgb, model_svr), meta_regressor=model_xgb, \\\n",
        "                                      use_features_in_secondary=True)\n",
        "  Test_Pred[\"stack\" + str(fold) + \"fld\"] = train_model(fold, model_stack_gen, 'StackGen', is_stack=True) \n",
        "\n",
        "print('Finished training all the models ...')\n",
        "\n",
        "def weight_models_pred(Test_Pred):\n",
        "  Y_test_pred = np.expm1(Test_Pred.iloc[:,0])\n",
        "  Test_Pred = Test_Pred.drop(Test_Pred.columns[[0]], axis=1)\n",
        "  for col in Test_Pred.columns:\n",
        "    if col not in ['stack0fld', 'stack1fld', 'stack2fld']:\n",
        "        Y_test_pred += np.expm1(Test_Pred[col])\n",
        "    else:\n",
        "        Y_test_pred += np.expm1(Test_Pred[col])*4\n",
        "  return Y_test_pred/30\n",
        "\n",
        "pandas_test = pd.DataFrame({'Id': test_data.Id, 'SalePrice': weight_models_pred(Test_Pred)})\n",
        "pandas_test.to_csv('/content/gdrive/My Drive/DM_Project_1/submission.csv', index=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training LGBM, XGB, E-NET, SVR, GBR, RIDGE, LASSO & STACK GEN ...\n",
            "[15:57:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "XGBoost Validation Root Mean Square Error : 0.10713882828532732\n",
            "Ridge Validation Root Mean Square Error : 0.13814481343624133\n",
            "Lasso Validation Root Mean Square Error : 0.13548596248818706\n",
            "ElasticNet Validation Root Mean Square Error : 0.1357232007247689\n",
            "GradientBoost Validation Root Mean Square Error : 0.11894529626634916\n",
            "SVR Validation Root Mean Square Error : 0.14172168472367247\n",
            "[15:58:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[15:58:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[15:58:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[15:58:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[15:58:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[15:59:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[15:59:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "StackGen Validation Root Mean Square Error : 0.10660191625118798\n",
            "[15:59:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "XGBoost Validation Root Mean Square Error : 0.13734899080977309\n",
            "Ridge Validation Root Mean Square Error : 0.13416549062324534\n",
            "Lasso Validation Root Mean Square Error : 0.13545295196799648\n",
            "ElasticNet Validation Root Mean Square Error : 0.13528900681549805\n",
            "GradientBoost Validation Root Mean Square Error : 0.13745602746365043\n",
            "SVR Validation Root Mean Square Error : 0.12919443135030195\n",
            "[16:00:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[16:00:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[16:00:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[16:00:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[16:00:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[16:01:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[16:01:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "StackGen Validation Root Mean Square Error : 0.1319948328274815\n",
            "[16:01:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "XGBoost Validation Root Mean Square Error : 0.11066632975623937\n",
            "Ridge Validation Root Mean Square Error : 0.11388078968439785\n",
            "Lasso Validation Root Mean Square Error : 0.11263316209203819\n",
            "ElasticNet Validation Root Mean Square Error : 0.1128696090158167\n",
            "GradientBoost Validation Root Mean Square Error : 0.10557519993056107\n",
            "SVR Validation Root Mean Square Error : 0.10196887941212136\n",
            "[16:02:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[16:02:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[16:02:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[16:02:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[16:03:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[16:03:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[16:03:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "StackGen Validation Root Mean Square Error : 0.1053492618169663\n",
            "Finished training all the models ...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}